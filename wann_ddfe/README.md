# Overview
This experiment trains an autoencoder to automatically extract features (32 float values) from MNIST images.
The notebook `1_generate_autoencoder.ipynb` trains the autoencoder on the MNIST dataset.
`2_mnist_convert_autoencoder.ipynb` uses the encoder part of the autoencoder to generate features from the MNIST train and test dataset.
`3_train_nn.ipynb` trains a standard 2-layer neural network on the extracted features to have something to compare the WANN to.

# WANN Training
Training the WANN takes a long time. Therefore running the training process on a server.
Here are the setup instructions to run it on a Ubuntu 18.04 server:

```bash
git clone https://github.com/fabioanderegg/brain-tokyo-workshop.git
cd brain-tokyo-workshop
sudo apt install -y python3-venv python3-dev build-essential libopenmpi-dev openmpi-bin
python3 -m venv venv
source venv/bin/activate
pip install wheel
pip install numpy mpi4py gym mnist cma
```

Copy files generated by `2_mnist_convert_autoencoder.ipynb` to brain-tokyo-workshop/WANNRelease:
* mnist_test_autoencoder.npy
* mnist_train_autoencoder.npy

Switch into the WANNRelease/WANN directory and run `train_mnist_autoencoder.sh` for some hours/days. This
generates the WANN architecture. Next, run `best_mnist_autoencoder.sh`. This extracts the best indiviual from the last
population of the WANNs. Switch to the WANNRelease/WANNTool directory.
Run `copy_mnist_autoencoder.sh`, then `finetune_mnist_autoencoder.sh`.
